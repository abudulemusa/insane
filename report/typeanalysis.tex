\section{Type Analysis}

\subsection{Introduction}
Object oriented languages such as Scala implement a feature called
\emph{dynamic dispatch}: the target of a method call is only determined at
runtime, based on the actual runtime type of the receiver. This feature is
essential in object oriented languages as it allows polymorphism. Consider the
Scala code in Figure~\ref{fig:ta:example1}: the compile type of \verb/obj/ in
\verb/A.test/ is \verb/A/, but the target of the method call could either be
\verb/A.foo/ or \verb/B.foo/, based on the actual type of the value of
\verb/obj/, which is only fully determined at runtime.

\begin{figure}[h]
    \centering
\begin{lstlisting}
class A {
  def test(obj: A) {
    obj.foo()
  }
  def foo() {
    println("A")
  }
}

class B extends A {
  override def foo() {
    println("B")
  }
}
\end{lstlisting}
    \caption{Dynamic dispatch}
    \label{fig:ta:example1}
\end{figure}

In general, every redefinitions of \emph{foo} in all subclasses of \emph{A}
could be targets of this method call. We formalize this concept by associating
for each method calls a set of targets $CT$. For this example, we have:

\begin{eqnarray*}
    CT(\verb/obj.foo()/@p) = \{A.foo, B.foo\}
\end{eqnarray*}
where $p$ is the program point--or label uniquely identifying the call.

Type analysis is responsible to compute this set of targets $CT$. For this
analysis to be valid, the set of targets should include all methods that could
be called at runtime. It may however be imprecise and include methods that will
never be called at runtime.

A simplistic implementation of this analysis would be to consider, given
the call \verb/rec.foo()/ where the receiver is of type \emph{T}, all subtypes
of \emph{T} where method \verb/foo()/ is redefined:

\begin{eqnarray*}
        SimpleCT(\verb/rec.foo(..)/@p) := \{C.foo ~ &|& C \in Classes \land \\
        && C \subtype type(\verb/rec/) \land \\
        && \verb/foo/ \in methods(C) \}
\end{eqnarray*}

where $methods(C)$ is the set of methods explicitely (re)defined in class $C$.
This analysis will be guaranteed to be valid given that the program typechecks,
but it will often be suboptimal, as illustrated in
Figure~\ref{fig:ta:example2}: even though the type of \verb/obj/ is \emph{A},
the only possible target of \verb/obj.foo()/ will be \verb/A.foo/.

\begin{figure}[h]
    \centering

\begin{lstlisting}
class A {
    def invoke {
        val obj = new A()
        obj.foo()
    }
    def foo() {
        println("A")
    }
}

class B extends A {
    override def foo() {
        println("B")
    }
}
\end{lstlisting}

    \caption{Precise call}
    \label{fig:ta:example2}
\end{figure}

\subsection{Our implementation}
Analyzing the targets of method calls can be reduced to analyzing the runtime
types of variables. Those types then fully determines the targets of the call.
Our analysis will thus analyze types that could occur at runtime, for every
variables present in the code. We distinguish three types of variables:
\begin{enumerate}
    \item \verb/A.f/: Field \verb/f/ of class \verb/A/.
    \item \verb/arg/: Argument \verb/arg/ of the function.
    \item \verb/locVar/: Local variable \verb/locVar/.
\end{enumerate}

For each of these variable occurrences in the code, our analysis will compute
the set of runtime types, that we will call \emph{ComputedTypes}, as opposed to
\emph{RuntimeTypes} which is the set of all types that could occur in runtime.
For the resulting type analysis to be valid, the set of computed object types
should be a superset of the types of values assigned to those variables at
runtime.  We thus have the following validity requirement:

\begin{eqnarray*}
    \forall v \in Variables: RuntimeTypes(v) \subseteq ComputedTypes(v)
\end{eqnarray*}

In order to compute the set of types at runtime, we need to track values
assigned to those variables. By doing that, we are immediately faced with two
non-trivial problems:
\begin{enumerate}
    \item The values of arguments are determined by call-sites, determining
    call-sites of a certain method is analogous to determining call targets,
    which is the purpose of type analysis.

    \item Fields can be assigned from multiple locations, within various
    methods. Again, determining whether those methods are
    called, and in which order, require type analysis.
\end{enumerate}

Both of those problems could be solved using a fix-point mechanism. However, at
the cost of some precision, we decided to fall back to a simple implementation
for both arguments and fields:

\begin{eqnarray*}
    ComputedTypes(\verb/A.f/) &:=& \{ T ~|~ T \subtype type(\verb/A.f/) \} \\
    ComputedTypes(\verb/arg/) &:=& \{ T ~|~ T \subtype type(\verb/arg/) \} \\
\end{eqnarray*}

where $type()$ is the type infered by the compiler.

For local variable, we run an flow-sensitive, context-insensitive, abstract
interpretation-based analysis. This analysis computes, at every program point,
the set of all types assigned to local variables. For this analysis to be
efficient, we represent the types of variables at each program point as a
tupple $(T_{sub}, T_{ex})$ where $T_{sub}$ is the set of types from which we
need to include all subtypes and $T_{ex}$ is the set of exact types. We enforce
the property that $T_{sub} \subseteq T_{ex}$.

We thus have a point-wise lattice \emph{L} over pairs of sets of types. Its
point-wise lowest upper bound operation is naturally defined as:
$$
    (T_{sub_a}, T_{ex_a}) \sqcup (T_{sub_b}, T_{ex_b}) = (T_{sub_a} \cup T_{sub_b}, T_{ex_a} \cup T_{ex_b})
$$
We outline in Figure~\ref{fig:ta:tf}
the transfer function for the most important statements.
\FloatBarrier
\begin{figure}[h]
    \centering

    \begin{tabular}{ l | l }
        Statement                 & Transfer function \\
        \hline
        \verb/r = new A/          & $facts[ r \mapsto (\{\}, \{ A \})]$ \\
        \verb/r = v/              & $facts[ r \mapsto facts(v)]$ \\
        \verb/r = null/           & $facts[ r \mapsto (\{\}, \{\})]$ \\
        \verb/r = A.f/            & $facts[ r \mapsto (\{type(\verb/A.f/)\}, \{type(\verb/A.f/)\}) ]$ \\
        \verb/r = rec.meth(..)/   & $facts[ r \mapsto (\{type(\verb/rec.meth/)\}, \{type(\verb/rec.meth/)\}) ]$ \\
        \verb/A.f = v/            & $facts$ (\emph{ignore}) \\
    \end{tabular}

    \caption{Transfer function excerpt}
    \label{fig:ta:tf}
\end{figure}

It is evident that this analysis terminates, as there is only finite ascending
chains in the lattice since $\mathcal{P}(Classes)$ is finite, and the transfer functions
is trivially monotonic.

When the fix-point is reached, we can derive the set of call targets \emph{CT}
for each method call using $facts$ computed at their program point:
\begin{eqnarray*}
    CT(\verb/rec.meth(..)/ @ p) := \{ T.meth ~|~ T \in resolve(facts@p(\verb/rec/)) \land \verb/meth/ \in methods(T) \}
\end{eqnarray*}
where $resolve$ is computing the entire set of types that the pair represents:

$$
resolve((T_{sub}, T_{ex})) := \{ T ~|~ \exists S \in T_{sub}. T \subtype S\} \cup T_{ex}
$$

This analysis provides us with a relatively precise information on call targets
that will be used to compute the initial callgraph. We argue that the obvious
lack of precision in the presence of fields and arguments is not problematic,
since the callgraph is only used to determine groups of mutually recursive
functions. A lack of precision in this analysis will only result in poorer time
performances, and will not impact the precision of the overall analysis. This
is partly explained by the fact that a more precise type analysis will be
performed during the pointer analysis phase. For this reason, this analysis is
arguably overly precise. However, we have seen that it is fast enough in
practice.
