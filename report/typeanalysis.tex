\section{Type Analysis}

\subsection{Introduction}
Object oriented languages such as Scala implement a feature called
\emph{dynamic dispatch}: the target of a method call is only determined at
runtime, based on the actual runtime type of the receiver. This feature is
essential in object oriented languages as it allows polymorphism. Consider the
Scala code in Figure~\ref{fig:ta:example1}: the compile type of \verb/obj/ in
\verb/A.test/ is \verb/A/, but the target of the method call could either be
\verb/A.foo/ or \verb/B.foo/, based on the actual type of the value of
\verb/obj/, which is only fully determined at runtime.

\begin{figure}[h]
    \centering
\begin{minipage}[tl]{0.6\linewidth}
    \centering
\lstset{linewidth=0.6\linewidth}
\begin{lstlisting}
class A {
  def test(obj: A) {
    obj.foo()
  }
  def foo() {
    println("A")
  }
}
\end{lstlisting}
\end{minipage}
\begin{minipage}[tl]{0.6\linewidth}
    \centering
\lstset{linewidth=0.6\linewidth}
\begin{lstlisting}

class B extends A {
  override def foo() {
    println("B")
  }
}
\end{lstlisting}
\end{minipage}
    \caption{Dynamic dispatch}
    \label{fig:ta:example1}
\end{figure}

In general, every redefinitions of \emph{foo} in all subclasses of \emph{A}
could be targets of this method call. We formalize this concept by associating
for each method calls a set of targets $CT$. For this example, we have:

\begin{eqnarray*}
    CT(\verb/obj.foo()/@p) = \{A.foo, B.foo\}
\end{eqnarray*}
where $p$ is the program point--or label uniquely identifying the call.

Type analysis is responsible to compute this set of targets $CT$. For this
analysis to be valid, the set of targets should include all methods that could
be called at runtime. It may however be imprecise and include methods that will
never be called at runtime.

A simplistic implementation of this analysis would be to consider, given
the call \verb/rec.foo()/ where the receiver is of type \emph{T}, all subtypes
of \emph{T} where method \verb/foo()/ is redefined:

\begin{eqnarray*}
        SimpleCT(\verb/rec.foo(..)/@p) := \{C.foo ~ &|& C \in Classes \land \\
        && C \subtypeeq type(\verb/rec/) \land \\
        && \verb/foo/ \in methods(C) \}
\end{eqnarray*}
where $methods(C)$ is the set of methods explicitely (re)defined in class $C$.
This analysis will be guaranteed to be valid given that the program typechecks,
but it will often be suboptimal, as illustrated in
Figure~\ref{fig:ta:example2}: even though the type of \verb/obj/ is \emph{A},
the only possible target of \verb/obj.foo()/ will be \verb/A.foo/.

\begin{figure}[h]
    \centering

\begin{minipage}[tl]{0.6\linewidth}
    \centering
\lstset{linewidth=0.6\linewidth}
\begin{lstlisting}
class A {
    def invoke {
        val obj = new A()
        obj.foo()
    }
    def foo() {
        println("A")
    }
}
\end{lstlisting}
\end{minipage}
\begin{minipage}[tl]{0.6\linewidth}
    \centering
\lstset{linewidth=0.6\linewidth}
\begin{lstlisting}

class B extends A {
    override def foo() {
        println("B")
    }
}
\end{lstlisting}
\end{minipage}
    \caption{Precise call}
    \label{fig:ta:example2}
\end{figure}

\subsection{Analysis}
Analyzing the targets of method calls can be reduced to analyzing the runtime
types of variables. Those types then fully determines the targets of the call.
Our analysis will thus analyze types that could occur at runtime, for every
variables present in the code. We distinguish three types of variables:
\begin{enumerate}
    \item \verb/A.f/: Field \verb/f/ of class \verb/A/.
    \item \verb/arg/: Argument \verb/arg/ of the function.
    \item \verb/locVar/: Local variable \verb/locVar/.
\end{enumerate}

For each of these variable occurrences in the code, our analysis will compute
the set of runtime types, that we will call \emph{ComputedTypes}, as opposed to
\emph{RuntimeTypes} which is the set of all types that could occur in runtime.
For the resulting type analysis to be valid, the set of computed object types
should be a superset of the types of values assigned to those variables at
runtime.  We thus have the following validity requirement:

\begin{eqnarray*}
    \forall v \in Variables: RuntimeTypes(v) \subseteq ComputedTypes(v)
\end{eqnarray*}

In order to compute the set of types at runtime, we need to track values
assigned to those variables. By doing that, we are immediately faced with two
non-trivial problems:
\begin{enumerate}
    \item The values of arguments are determined by call-sites, determining
    call-sites of a certain method is analogous to determining call targets,
    which is the purpose of type analysis.

    \item Fields can be assigned from multiple locations, within various
    methods. Again, determining whether those methods are
    called, and in which order, require type analysis.
\end{enumerate}

Both of those problems could be solved using a fix-point mechanism. However, at
the cost of some precision, we decided to fall back to a simple implementation
for both arguments and fields:

\begin{eqnarray*}
    ComputedTypes(\verb/A.f/) &:=& \{ T ~|~ T \subtypeeq type(\verb/A.f/) \} \\
    ComputedTypes(\verb/arg/) &:=& \{ T ~|~ T \subtypeeq type(\verb/arg/) \} \\
\end{eqnarray*}
where $type()$ is the type inferred by the compiler.

For local variable, we run an flow-sensitive, context-insensitive, abstract
interpretation-based analysis. This analysis computes, at every program point,
the set of all types assigned to local variables. For this analysis to be
efficient, we represent the types as follows:
\begin{eqnarray*}
    TypeInfo &:=& \langle T_{sub} \subtypeeq Types, T_{ex} \subtypeeq Types\rangle \\
    Types    &:=& Classes \cup \{ Array[T] ~|~ T \in Types \} \\
\end{eqnarray*}

We split the type information into two sets $T_{sub}$ and $T_{ex}$. $T_{ex}$
contains "exact" types, while $T_{sub}$ contains types from which we need to
also consider subtypes. This split is useful for two reasons: first, it allows
us to keep an small representation for subtypes of, i.e. Object, second it
lets us delay the resolution of the actual types until the last moment.
Globally, storing runtime types with that representation is much more memory
efficient than storing a plain set of potential types.

We thus have a point-wise lattice \emph{L} over pairs of sets of types. Its
point-wise lowest upper bound operation is naturally defined as:
$$
    \langle T_{sub_a}, T_{ex_a} \rangle \sqcup  \langle T_{sub_b}, T_{ex_b} \rangle =  \langle T_{sub_a} \cup T_{sub_b}, T_{ex_a} \cup T_{ex_b} \rangle
$$
We outline in Figure~\ref{fig:ta:tf}
the abstraction function for important values.
\FloatBarrier
\begin{figure}[h]
    \centering

    \begin{tabular}{ l | l }
        Expression $ex$       & Abstract Value $\alpha(ex)$\\
        \hline
        \verb/new A/          & $\langle \emptyset, \{ A \} \rangle$ \\
        \verb/null/           & $\langle \emptyset, \emptyset \rangle$ \\
        \verb/A.f/            & $\langle\{type(\verb/A.f/)\}, \{type(\verb/A.f/)\} \rangle$ \\
        \verb/rec.meth(..)/   & $\langle\{type(\verb/rec.meth/)\}, \{type(\verb/rec.meth/)\} \rangle$ \\
    \end{tabular}

    \caption{Abstraction function $\alpha$}
    \label{fig:ta:tf}
\end{figure}

The number of used types, although infinite in theory, is finite for a given
program given that typechecks.  For this reason, we can argue that this
analysis terminates, since there are only finite ascending chains in the
lattice as $\mathcal{T}(Types)$ is finite. We also have a trivially monotonic
transfer function.

When the fix-point is reached, we can derive the set of call targets \emph{CT}
for each method call using $facts$ computed at their program point:
\begin{eqnarray*}
    CT(\verb/rec.meth(..)/ @ p) := \{ T.meth ~|~ T \in \gamma(facts@p(\verb/rec/)) \land \verb/meth/ \in methods(T) \}
\end{eqnarray*}
where $\gamma$ is the concretisation function, computing the entire set of
types that the pair represents:

$$
\gamma(\langle T_{sub}, T_{ex} \rangle ) := \{ T ~|~ \exists S \in T_{sub}. T \subtype S\} \cup T_{ex}
$$

This analysis provides us with a relatively precise information on call targets
that will be used to compute the initial callgraph. We argue that the obvious
lack of precision in the presence of fields and arguments is not problematic,
since the callgraph is only used to determine groups of mutually recursive
functions. A lack of precision in this analysis will only result in poorer time
performances, and will not impact the precision of the overall analysis. This
is partly explained by the fact that a more precise type analysis will be
performed during the pointer analysis phase. For this reason, this analysis is
arguably overly precise. However, we have seen that it is sufficiently fast in
practice.
