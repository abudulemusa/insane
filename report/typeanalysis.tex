\section{Type Analysis}

\subsection{Introduction}
Object oriented languages such as Scala implement \emph{dynamic dispatch}: the
target of a method call is only determined at runtime, based on the actual
runtime type of the receiver. This feature is essential in object oriented
languages as it allows subtype polymorphism. Consider the Scala code in
Figure~\ref{fig:ta:example1}: the declared type of \lstinline{obj} in
\lstinline{A.test} is \lstinline{A}, but the target of the method call could
either be \lstinline{A.foo} or \lstinline{B.foo}, based on the actual type of
the value of \lstinline{obj}, which is only fully determined at runtime.

\begin{figure}[h]
    \centering
\begin{minipage}[tl]{0.6\linewidth}
    \centering
\lstset{linewidth=0.6\linewidth}
\begin{lstlisting}
class A {
  def run {
    test(new B)
  }
  def test(obj: A) {
    obj.foo()
  }
  def foo() {
    println("A")
  }
}
\end{lstlisting}
\end{minipage}
\begin{minipage}[tl]{0.6\linewidth}
    \centering
\lstset{linewidth=0.6\linewidth}
\begin{lstlisting}

class B extends A {
  override def foo() {
    println("B")
  }
}
\end{lstlisting}
\end{minipage}
    \caption{Dynamic dispatch}
    \label{fig:ta:example1}
\end{figure}

In general, every redefinitions of \lstinline{foo} in all subclasses of
\emph{A} could be targets of this method call. We formalize this concept
by associating for each method call a set of targets, $CT$. For this example,
we have:
\begin{eqnarray*}
    CT(\verb/obj.foo()/@p) = \{A.foo, B.foo\}
\end{eqnarray*}
where $p$ is the program point--or label uniquely identifying the call.

Type analysis is responsible for computing this set of targets $CT$. For this
analysis to be valid, the set of targets should include all methods that could
be called at runtime. It may however be imprecise and include methods that will
never be called at runtime.

A simplistic implementation of this analysis would be the following. Consider a
call \lstinline{rec.foo()} where the receiver \lstinline{rec} is of type
\emph{T}, all subtypes of \emph{T} where method \lstinline{foo()} is redefined:
\begin{eqnarray*}
        SimpleCT(\verb/rec.foo(..)/@p) := \{C.foo ~ &|& C \in Classes \land \\
        && C \subtypeeq type(\verb/rec/) \land \\
        && \verb/foo/ \in methods(C) \}
\end{eqnarray*}
where $methods(C)$ is the set of methods explicitly (re)defined in class $C$.
This analysis is sound, but it will often be imprecise, as illustrated in
Figure~\ref{fig:ta:example2}. Even though the type of \lstinline{obj} is
\emph{A}, so subtypes are $\{A, B\}$, the only possible target of
\lstinline{obj.foo()} is \lstinline{A.foo}.

\begin{figure}[h]
    \centering

\begin{minipage}[tl]{0.6\linewidth}
    \centering
\lstset{linewidth=0.6\linewidth}
\begin{lstlisting}
class A {
    def invoke {
        val obj = new A()
        obj.foo()
    }
    def foo() {
        println("A")
    }
}
\end{lstlisting}
\end{minipage}
\begin{minipage}[tl]{0.6\linewidth}
    \centering
\lstset{linewidth=0.6\linewidth}
\begin{lstlisting}

class B extends A {
    override def foo() {
        println("B")
    }
}
\end{lstlisting}
\end{minipage}
    \caption{Example of imprecision of the simplistic approach}
    \label{fig:ta:example2}
\end{figure}

However, we note that a lack of precision in this analysis will only result in
poorer time performances, and will not impact the precision of the overall
analysis. Indeed, this analysis is only used to build the initial call graph.
Even though the simplistic approach described before might be sufficient in
practice, we define a slightly more precise type analysis for this call graph
generation. An even more precise type analysis will be performed during the
pointer analysis phase.

\subsection{Analysis}
Analyzing the targets of method calls can be reduced to analyzing the runtime
types of variables. Those types then fully determines the targets of the call.
Our analysis will thus analyze types that could occur at runtime, for every
variables present in the code. We distinguish three types of variables:
\begin{enumerate}
    \item \lstinline{A.f}: Field \lstinline{f} of class \lstinline{A}.
    \item \lstinline{arg}: Argument \lstinline{arg} of the function.
    \item \lstinline{locVar}: Local variable \lstinline{locVar}.
\end{enumerate}

For each of these variable occurrences in the code, our analysis will compute
the set of runtime types, that we will call \emph{ComputedTypes}, as opposed to
\emph{RuntimeTypes} which is the set of all types that could occur in runtime.
For the resulting type analysis to be valid, the set of computed object types
should be a superset of the types of values assigned to those variables at
runtime.  We thus have the following validity requirement:
\begin{eqnarray*}
    \forall v \in Variables: RuntimeTypes(v) \subseteq ComputedTypes(v)
\end{eqnarray*}

To compute the set of types at runtime, we track values assigned to those
variables. When doing this, we immediately face two non-trivial problems:
\begin{enumerate}
    \item The values of arguments are determined by call-sites, determining
    call-sites of a certain method is analogous to determining call targets,
    which is the purpose of type analysis.

    \item Fields can be assigned from multiple locations, within various
    methods. Again, determining whether those methods are
    called, and in which order, require type analysis.
\end{enumerate}

Both of those problems could be solved using a fix-point mechanism. However, at
the cost of some precision, we decided to fall back to a simple implementation
for both arguments and fields:
\begin{eqnarray*}
    ComputedTypes(\verb/A.f/) &:=& \{ T ~|~ T \subtypeeq type(\verb/A.f/) \} \\
    ComputedTypes(\verb/arg/) &:=& \{ T ~|~ T \subtypeeq type(\verb/arg/) \} \\
\end{eqnarray*}
where $type()$ is the statically declared type.

For local variables, we run a flow-sensitive, context-insensitive, abstract
interpretation-based analysis. This analysis computes, at every program point,
the set of all types assigned to local variables. For this analysis to be
efficient, we split the type information into two sets $T_{sub}$ and $T_{ex}$.
$T_{ex}$ contains "exact" types, while $T_{sub}$ contains types from which we
need to also consider subtypes. This split is useful for two reasons: first, it
allows us to keep a small representation for subtypes of, e.g. Object. Second,
it lets us delay the resolution of the actual types until the last moment.
Globally, storing runtime types with that representation is much more memory
efficient than storing a plain set of potential types. We formally define the
type information as follows:
\begin{eqnarray*}
    TypeInfo &:=& \langle T_{sub} \subtypeeq Types, T_{ex} \subtypeeq Types\rangle \\
    Types    &:=& Classes \cup \{ Array[T] ~|~ T \in Types \} \\
\end{eqnarray*}

We thus have a point-wise lattice \emph{L} over pairs of sets of types. Its
point-wise lowest upper bound operation is naturally defined as:
$$
    \langle T_{sub_a}, T_{ex_a} \rangle \sqcup  \langle T_{sub_b}, T_{ex_b} \rangle =  \langle T_{sub_a} \cup T_{sub_b}, T_{ex_a} \cup T_{ex_b} \rangle
$$
We outline in Figure~\ref{fig:ta:tf} the abstraction function for important
values.
\begin{figure}[h]
    \centering

    \begin{tabular}{ l | l }
        Expression $ex$       & Abstract Value $\alpha(ex)$\\
        \hline
        \verb/new A/          & $\langle \emptyset, \{ A \} \rangle$ \\
        \verb/null/           & $\langle \emptyset, \emptyset \rangle$ \\
        \verb/A.f/            & $\langle\{type(\verb/A.f/)\}, \{type(\verb/A.f/)\} \rangle$ \\
        \verb/rec.meth(..)/   & $\langle\{type(\verb/rec.meth/)\}, \{type(\verb/rec.meth/)\} \rangle$ \\
    \end{tabular}

    \caption{Abstraction function $\alpha$, where $type()$ returns the declared
    type.}
    \label{fig:ta:tf}
\end{figure}

The number of used types, although infinite in theory, is finite for a given
program given that it typechecks. For this reason, we can argue that this
analysis terminates, since there are only finite ascending chains in the
lattice as $\mathcal{T}(Types)$ is finite. We also have naturally monotonic
transfer functions.

When the fix-point is reached, we can derive the set of call targets \emph{CT}
for each method call using $facts$ computed at their program point:
\begin{eqnarray*}
    CT(\verb/rec.meth(..)/ @ p) := \{ T.meth ~|~ T \in \gamma(facts@p(\verb/rec/)) \land \verb/meth/ \in methods(T) \}
\end{eqnarray*}
where $\gamma$ is the concretisation function, computing the entire set of
types that the pair represents:
$$
\gamma(\langle T_{sub}, T_{ex} \rangle ) := \{ T ~|~ \exists S \in T_{sub}. T \subtype S\} \cup T_{ex}
$$

This analysis provides us with a relatively precise information on call
targets. We believe that the obvious lack of precision in the presence of
fields and arguments is not problematic, since the call graph is only used to
determine groups of mutually recursive functions. For this reason, this
analysis might even be overly precise. However, we have seen that it is
sufficiently fast in practice.
